{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Paths to the Data\n",
    "# -------------------------\n",
    "root_dir = \"Datasets\"\n",
    "cleaned_data_path = os.path.join(root_dir, \"df_postwar.pkl\")\n",
    "\n",
    "# -------------------------\n",
    "# Copy images from Drive to local Colab disk\n",
    "# -------------------------\n",
    "local_image_dir = \"Datasets/images_resized\"\n",
    "os.makedirs(local_image_dir, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# Load tabular data\n",
    "# -------------------------\n",
    "df_postwar = pd.read_pickle(cleaned_data_path)\n",
    "df_postwar['Log Price'] = np.log1p(df_postwar['Price Sold USD'])\n",
    "print(\"Data loaded. Columns:\", df_postwar.columns.tolist())\n",
    "\n",
    "# -------------------------\n",
    "# Assign local image paths\n",
    "# -------------------------\n",
    "def get_image_path(idx):\n",
    "    filename = f\"art_{idx:05d}.jpg\"\n",
    "    path = os.path.join(local_image_dir, filename)\n",
    "    return path if os.path.exists(path) else None\n",
    "\n",
    "df_postwar['Image Path'] = df_postwar.index.to_series().apply(get_image_path)\n",
    "df_postwar = df_postwar[df_postwar['Image Path'].notnull()]\n",
    "print(f\"{len(df_postwar)} artworks with valid image files in local disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# STEP 1: VARIABLE TYPES\n",
    "# -------------------------\n",
    "target_col = 'Log Price'\n",
    "numerical_cols = [\n",
    "    'Area',\n",
    "    'Sale Year',\n",
    "    'CPI_US',\n",
    "    'Artist Ordered Median Price']\n",
    "cat_cols = [\n",
    "    'Paint Final Imputed Collapsed',\n",
    "    'Material Final Imputed Collapsed',\n",
    "    'Artist Name',\n",
    "    'Auction House',\n",
    "    'Country',\n",
    "    'Birth Period',\n",
    "    'Alive Status'\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# STEP 2: ENCODE CATEGORICAL VARIABLES\n",
    "# -------------------------\n",
    "cat_vocab_sizes = {}\n",
    "for col in cat_cols:\n",
    "    df_postwar[col] = df_postwar[col].astype('category')\n",
    "    df_postwar[col + '_idx'] = df_postwar[col].cat.codes.clip(lower=0)\n",
    "    cat_vocab_sizes[col] = len(df_postwar[col].cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# STEP 3: SPLIT + NORMALIZE + FEATURE ADD\n",
    "# -------------------------\n",
    "df_postwar = df_postwar.sort_values('Sale Date Cleaned').reset_index(drop=True)\n",
    "df_postwar['Sale Year'] = pd.to_datetime(df_postwar['Sale Date Cleaned']).dt.year\n",
    "\n",
    "def add_ordered_artist_median(df):\n",
    "    df = df.sort_values('Sale Date Cleaned').copy()\n",
    "    df['Artist Ordered Median Price'] = (\n",
    "        df.groupby('Artist Name')['Price Sold USD']\n",
    "          .transform(lambda x: x.shift().expanding().median()))\n",
    "\n",
    "    # New Variable: Artist Sale Count\n",
    "    df['Artist Sale Count'] = (\n",
    "        df.groupby('Artist Name')\n",
    "          .cumcount()\n",
    "    )\n",
    "\n",
    "    return df[df['Artist Ordered Median Price'].notnull()].copy()\n",
    "\n",
    "train_df = add_ordered_artist_median(df_postwar[df_postwar['Sale Year'] <= 2014])\n",
    "val_df = add_ordered_artist_median(df_postwar[(df_postwar['Sale Year'] > 2014) & (df_postwar['Sale Year'] <= 2018)])\n",
    "test_df = add_ordered_artist_median(df_postwar[df_postwar['Sale Year'] > 2018])\n",
    "\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n",
    "val_df[numerical_cols] = scaler.transform(val_df[numerical_cols])\n",
    "test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# STEP 4: DATASET & DATALOADER\n",
    "# -------------------------\n",
    "# Converts tabular data into a format PyTorch so that it can be fed to NN\n",
    "\n",
    "# The class saves the categorical data as indices, and the numerical data as floats\n",
    "class ArtPriceDataset(Dataset):\n",
    "\n",
    "    #Initializes the dataset by saving the cat, numerical, image paths, and the target\n",
    "    def __init__(self, df, cat_cols, num_cols, target_col, transform = None):\n",
    "\n",
    "        print(\"ðŸ“¦ Initializing ArtPriceDataset...\")\n",
    "\n",
    "        self.cat_data = df[[col + '_idx' for col in cat_cols]].values.astype('int64').astype('int64')\n",
    "        self.num_data = df[num_cols].values.astype('float32')\n",
    "        self.targets = df[target_col].values.astype('float32')\n",
    "        self.image_paths = df['Image Path'].values\n",
    "        print(f\"âœ… Dataset contains {len(self.targets)} samples.\")\n",
    "\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self): # returns number of rows\n",
    "        return len(self.targets)\n",
    "\n",
    "    # For a given row, it returns a dictionary with the categorical and numerical data, and the target\n",
    "    # {'cat': ..., 'num': ..., 'img': ..., 'target': ...} for that artwork\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 2:\n",
    "          print(f\"ðŸ“¸ Loading item {idx}: {self.image_paths[idx]}\")\n",
    "\n",
    "        cat_tensor = torch.tensor(self.cat_data[idx], dtype=torch.long)\n",
    "        num_tensor = torch.tensor(self.num_data[idx], dtype=torch.float32)\n",
    "        target_tensor = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "\n",
    "        # Load and transform image\n",
    "        image_path = self.image_paths[idx]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            image_tensor = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading image {image_path}: {e}\")\n",
    "            image_tensor = torch.zeros(3, 224, 224)\n",
    "\n",
    "        return {\n",
    "            'cat': cat_tensor,\n",
    "            'num': num_tensor,\n",
    "            'img': image_tensor,\n",
    "            'target': target_tensor\n",
    "        }\n",
    "\n",
    "# Defining a shared image transform\n",
    "# Resizes the image to 224x224 and converts it to a tensor\n",
    "# Tensor = data cotainer like an arrsay but any dimension -> ie. (64, 3, 224, 224) Batch Ã— Channels Ã— Height Ã— Width\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create datasets using the transform\n",
    "train_ds = ArtPriceDataset(train_df, cat_cols, numerical_cols, target_col, transform=image_transform)\n",
    "val_ds = ArtPriceDataset(val_df, cat_cols, numerical_cols, target_col, transform=image_transform)\n",
    "test_ds = ArtPriceDataset(test_df, cat_cols, numerical_cols, target_col, transform=image_transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "# Wraps data in batches, shuffles it during training, and feeds it to the model\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# STEP 5: MAIN MULTIMODAL MODEL\n",
    "# -------------------------\n",
    "# Defining the multimodal neural network\n",
    "\n",
    "class ArtPriceMultimodalNN(nn.Module):\n",
    "\n",
    "    def __init__(self, cat_vocab_sizes, num_numerical):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. Categorical embeddings\n",
    "        self.embeddings = nn.ModuleList() # Initialize a list of embedding layers (one for each cat variable)\n",
    "        self.embedding_dims = [] # Initialize a list of embedding output sizes\n",
    "\n",
    "        for vocab_size in cat_vocab_sizes.values(): # Calculates the embedding dimensions for each categorical variable\n",
    "            emb_dim = min(50, (vocab_size + 1) // 2) # embedding dimension per cat variable\n",
    "            self.embeddings.append(nn.Embedding(vocab_size, emb_dim))\n",
    "            self.embedding_dims.append(emb_dim)\n",
    "        self.total_emb_dim = sum(self.embedding_dims)\n",
    "\n",
    "        # 2. Pretrained ResNet50 image encoder (without final layer)\n",
    "        base_resnet = resnet50(weights=ResNet50_Weights.DEFAULT) # load pretrained ResNet50\n",
    "\n",
    "        # Freeze all layers\n",
    "        for param in base_resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze only the second-to-last block (layer4)\n",
    "        for param in base_resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.image_encoder = nn.Sequential(*list(base_resnet.children())[:-1]) # remove fc layer, so outputs a 2048-dim feature vector for each image\n",
    "\n",
    "\n",
    "        # 3. Fully connected head (Tabular + Image features)\n",
    "        # Three Layered NN that concats the categorical, numerical, and image features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.total_emb_dim + num_numerical + 2048, 2048), # embeddings + numerical + image features\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2048, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1000, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, cat_data, num_data, image_data):\n",
    "        # Embeddings\n",
    "        embedded = [emb(cat_data[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        cat_out = torch.cat(embedded, dim=1) # Concatenates all the embedded outputs into a single vector\n",
    "\n",
    "        # Image encoding\n",
    "        img_features = self.image_encoder(image_data)  # Feeds images through ResNet50\n",
    "        img_out = img_features.view(img_features.size(0), -1)  # flatten to [batch, 2048], makes ready for concatenation\n",
    "\n",
    "        # Combine all features: categorical embeddings + numerical + image vector\n",
    "        x = torch.cat([cat_out, num_data, img_out], dim=1)\n",
    "        return self.fc(x).squeeze() # squezze to dimension [batch, 1] for the final output (single price per artwork)\n",
    "\n",
    "model = ArtPriceMultimodalNN(cat_vocab_sizes=cat_vocab_sizes, num_numerical=len(numerical_cols))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# STEP 6: TRAINING WITH EARLY STOPPING\n",
    "# -------------------------\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs=50, patience=10):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_mae = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_mae\": [], \"val_mae\": []}\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\n Starting Epoch {epoch+1}/{n_epochs}...\")\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        model.train()\n",
    "        y_train_true = []\n",
    "        y_train_pred = []\n",
    "\n",
    "        train_start = time.time()\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            if i % 5 == 0:\n",
    "               print(f\"Train batch {i+1}/{len(train_loader)}\")\n",
    "\n",
    "            cat = batch['cat'].to(device)\n",
    "            num = batch['num'].to(device)\n",
    "            img = batch['img'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(cat, num, img)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            y_train_true.extend(target.detach().cpu().numpy())\n",
    "            y_train_pred.extend(output.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        train_mae = mean_absolute_error(y_train_true, y_train_pred)\n",
    "        print(f\"Finished training loop in {train_time:.2f} sec. Train MAE: {train_mae:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        y_val_true = []\n",
    "        y_val_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                cat = batch['cat'].to(device)\n",
    "                num = batch['num'].to(device)\n",
    "                img = batch['img'].to(device)\n",
    "                target = batch['target'].to(device)\n",
    "\n",
    "                output = model(cat, num, img)\n",
    "\n",
    "                y_val_true.extend(target.cpu().numpy())\n",
    "                y_val_pred.extend(output.cpu().numpy())\n",
    "\n",
    "        val_mae = mean_absolute_error(y_val_true, y_val_pred)\n",
    "        history['train_mae'].append(train_mae)\n",
    "        history['val_mae'].append(val_mae)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}: Train MAE = {train_mae:.4f}, Val MAE = {val_mae:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# STEP 7: RUN TRAINING\n",
    "# -------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "trained_model, history = train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# STEP 8: VISUALIZE LOSS CURVE\n",
    "# -------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history['train_mae'], label='Train MAE')\n",
    "plt.plot(history['val_mae'], label='Validation MAE')\n",
    "plt.title('MAE per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# STEP 9: PREDICTIONS & RESIDUALS\n",
    "# -------------------------\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        cat = batch['cat'].to(device)\n",
    "        num = batch['num'].to(device)\n",
    "        img = batch['img'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "\n",
    "        output = trained_model(cat, num, img)\n",
    "\n",
    "        y_true.extend(target.cpu().numpy())\n",
    "        y_pred.extend(output.cpu().numpy())\n",
    "\n",
    "# Convert to arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "residuals = y_true - y_pred\n",
    "mae_val = np.mean(np.abs(residuals))\n",
    "print(f\"Final Validation MAE: {mae_val:.4f}\")\n",
    "\n",
    "# Plot: Predicted vs Actual\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_true, y_pred, alpha=0.5)\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], '--', color='gray')\n",
    "plt.title('Predicted vs Actual Log Prices')\n",
    "plt.xlabel('Actual Log Price')\n",
    "plt.ylabel('Predicted Log Price')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot: Residuals\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(residuals, bins=50, alpha=0.7)\n",
    "plt.title('Residuals (Actual - Predicted)')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
