{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import shap\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Load Training and Validation Data\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "train_df = pd.read_pickle(\"Datasets/train_df.pkl\")\n",
    "val_df = pd.read_pickle(\"Datasets/val_df.pkl\")\n",
    "test_df = pd.read_pickle(\"Datasets/test_df.pkl\")\n",
    "\n",
    "# Define target variable (log price)\n",
    "y_train_log = np.log(train_df['Price Sold USD'])\n",
    "y_val_log = np.log(val_df['Price Sold USD'])\n",
    "y_test_log = np.log(test_df['Price Sold USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# XGBoost Modeling: One-Hot Encoding Categorical Features\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Define Categorical Columns for One-Hot Encoding\n",
    "categorical_cols = [\n",
    "    'Paint Imputed',\n",
    "    'Material Imputed',\n",
    "    'Country',\n",
    "    'Auction House',\n",
    "    'Alive Status'\n",
    "]\n",
    "\n",
    "# Ensure all categorical columns are string type (and no NaNs)\n",
    "for df_ in [train_df, val_df]:\n",
    "    df_[categorical_cols] = df_[categorical_cols].astype(str).fillna(\"Missing\")\n",
    "\n",
    "\n",
    "# One-hot encode categorical variables using training data\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoder.fit(train_df[categorical_cols])\n",
    "\n",
    "def encode_cats(df):\n",
    "    encoded = encoder.transform(df[categorical_cols])\n",
    "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols), index=df.index)\n",
    "    return pd.concat([df.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "\n",
    "train_encoded = encode_cats(train_df)\n",
    "val_encoded = encode_cats(val_df)\n",
    "test_encoded = encode_cats(test_df)\n",
    "\n",
    "# Final feature list\n",
    "features = (\n",
    "    list(encoder.get_feature_names_out(categorical_cols)) +\n",
    "    ['Log Area', 'Artist Ordered Avg Price',\n",
    "     'CPI_US', 'Artist Sale Count', 'Birth Period Ordinal',\n",
    "     'Artist Cumulative Price']\n",
    ")\n",
    "\n",
    "# Targets (log-transformed)\n",
    "X_train, y_train_log = train_encoded[features], np.log1p(train_encoded['Price Sold USD'])\n",
    "X_val, y_val_log = val_encoded[features], np.log1p(val_encoded['Price Sold USD'])\n",
    "X_test, y_test_log = test_encoded[features], np.log1p(test_encoded['Price Sold USD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# XGBoost Modeling:  Define Objective Function for Optuna Tuning\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train_log,\n",
    "        eval_set=[(X_val, y_val_log)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    val_preds_log = model.predict(X_val)\n",
    "    return mean_absolute_error(y_val_log, val_preds_log)\n",
    "\n",
    "# Run Optuna Optimization for XGBoost\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best MAE (log):\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# XGBoost: Train Final Model with Best Parameters\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "best_xgb = XGBRegressor(**study.best_params, random_state=42)\n",
    "best_xgb.fit(\n",
    "    X_train, y_train_log,\n",
    "    eval_set=[(X_val, y_val_log)],\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# XGBoost: Evaluate the Optimized XGBoost Model on Validation Set\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "val_preds_log = best_xgb.predict(X_val)\n",
    "val_preds = np.exp(val_preds_log)\n",
    "\n",
    "mae_usd = mean_absolute_error(val_encoded['Price Sold USD'], val_preds)\n",
    "mae_log = mean_absolute_error(y_val_log, val_preds_log)\n",
    "\n",
    "print(f\"Validation MAE (USD): ${mae_usd:,.2f}\")\n",
    "print(f\"Validation MAE (Log): {mae_log:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# XGBoost: Evaluate on Test Set\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "test_preds_log = best_xgb.predict(X_test)\n",
    "test_preds_usd = np.exp(test_preds_log)\n",
    "\n",
    "mae_usd = mean_absolute_error(test_encoded['Price Sold USD'], test_preds_usd)\n",
    "mae_log = mean_absolute_error(y_test_log, test_preds_log)\n",
    "\n",
    "print(f\"Validation MAE (USD): ${mae_usd:,.2f}\")\n",
    "print(f\"Validation MAE (Log): {mae_log:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# XGBoost: Visualization â€“ Residuals & Actual vs Predicted\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Residuals (Log scale)\n",
    "residuals_log = y_val_log - val_preds_log\n",
    "\n",
    "# Actual vs. Predicted (Log)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_val_log, val_preds_log, alpha=0.3, edgecolor='k')\n",
    "plt.plot([y_val_log.min(), y_val_log.max()], [y_val_log.min(), y_val_log.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Log Price')\n",
    "plt.ylabel('Predicted Log Price')\n",
    "plt.title('XGBoost: Actual vs Predicted Log Prices')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(residuals_log, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title(\"XGBoost Residuals (Log Price)\")\n",
    "plt.xlabel(\"Actual - Predicted (Log Scale)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# XGBoost: SHAP Values\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "explainer = shap.Explainer(best_xgb, X_train, feature_names=features)\n",
    "shap_values = explainer(X_val)\n",
    "\n",
    "shap.summary_plot(shap_values, X_val, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, X_val)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
