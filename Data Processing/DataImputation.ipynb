{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "---------------------------------------------------------\n",
    "Data Imputation and Grouping Script (Step 2): Paint & Material\n",
    "---------------------------------------------------------\n",
    "\n",
    "This script performs grouping, cleaning, and imputation of missing values for the 'Paint' and 'Material' columns \n",
    "in the cleaned art auction dataset from Step 1. It ensures consistent terminology, reduces cardinality, \n",
    "and imputes missing values using artist-specific distributions.\n",
    "\n",
    "Main Tasks:\n",
    "-----------\n",
    "1. **Load Data**:\n",
    "   - Loads the processed DataFrame from Step 1 (`DataProcessing_Step1_df.pkl`).\n",
    "\n",
    "2. **Paint Grouping**:\n",
    "   - Maps exact and composite paint descriptions (e.g., 'ink, watercolor') into consistent grouped labels.\n",
    "   - Uses rule-based and fallback keyword matching to assign a single paint group per artwork.\n",
    "   - Collapses rarely used paint types into 'other', keeping top 28 types.\n",
    "\n",
    "3. **Material Grouping**:\n",
    "   - Maps specific and compound terms (e.g., 'canvas, paper', 'fiberboard') into unified categories.\n",
    "   - Applies multi-stage refinement to consolidate materials like 'panel', 'board', and 'canvas'.\n",
    "   - Collapses rarely used materials into 'other', keeping top 20 types.\n",
    "\n",
    "4. **Imputation Strategy**:\n",
    "   - Identifies artists with fewer than 35% missing data in 'Paint' or 'Material' and imputes missing values \n",
    "     based on observed co-occurrences of paint and material combinations.\n",
    "   - A second round of imputation targets high-volume artists (≥150 known entries) not covered in round one.\n",
    "   - Imputation is performed using artist-specific conditional distributions (probabilistic sampling).\n",
    "\n",
    "5. **Final Cleanup**:\n",
    "   - Drops remaining rows with missing 'Paint', 'Material', or 'Area'.\n",
    "   - Outputs a cleaned DataFrame (`df_final`) ready for modeling.\n",
    "\n",
    "Outputs:\n",
    "--------\n",
    "- `df_final` : Final cleaned DataFrame with imputed and grouped `Paint` and `Material` columns:\n",
    "    - `Paint Final Imputed Collapsed`\n",
    "    - `Material Final Imputed Collapsed`\n",
    "- `missing_summary`: Summary of missing values per column after all filtering and imputation.\n",
    "\n",
    "Next Step:\n",
    "----------\n",
    "- Feature engineering and modeling using the cleaned and imputed dataset.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('Art-Valuation-in-Auction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Pickle File Function\n",
    "def read_pickle_to_dataframe(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = []\n",
    "            while True:\n",
    "                try:\n",
    "                    obj = pickle.load(f)\n",
    "                    if isinstance(obj, list):\n",
    "                        data.extend(obj)\n",
    "                    else:\n",
    "                        data.append(obj)\n",
    "                except EOFError:\n",
    "                    break\n",
    "        print(f\"Loaded {len(data)} records.\")\n",
    "        df = pd.DataFrame(data)\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading pickle file: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data from Step 1\n",
    "df = pd.read_pickle(\"Datasets/DataProcessing_Step1_df.pkl\")\n",
    "\n",
    "# Check\n",
    "print(\"Data Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Values of Paint\n",
    "unique_paints = df['Paint'].dropna().unique()\n",
    "print(f\"Unique Paints ({len(unique_paints)}):\")\n",
    "\n",
    "top_paints = df['Paint'].str.strip().str.lower().value_counts()\n",
    "print(top_paints[:20])\n",
    "print(f\"Number of unique paint categories: {df['Paint'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Define Grouping Rules for Paint\n",
    "# ----------------------------------------\n",
    "\n",
    "    ## Exact matches ##\n",
    "# These sets contain known variants/synonyms of key paint categories.\n",
    "# Each key in the dictionary is a standardized category label (e.g., 'oil', 'acrylic'),\n",
    "# and the associated set contains all strings that should be grouped into that label.\n",
    "exact_matches = {\n",
    "    'oil': {'oil', 'oil wash', 'oil, s', 'huile sur toile', 'oil painting', 'each oil'},\n",
    "    'acrylic': {'acrylic', 'acrylic paint', 'acrylic, s', 'acrylics'},\n",
    "    'watercolor': {'watercolor', 'watercolor heightened with white', 'opaque white, watercolor', 'watercolor drawing', 'watercolor pair'},\n",
    "    'mixed media': {'mixed media', 'collage', 'collage, mixed media', 'mixed technique', 'paper collage'},\n",
    "    'ink': {'ink', 'india ink', 'ink wash', 'color, ink', 'ink, wash', 'colour, ink'},\n",
    "    'pencil': {'pencil', 'graphite', 'lead pencil', 'pencil drawing', 'black pencil', 'colored pencil'},\n",
    "    'pastel': {'pastel', 'crayon', 'oil pastel', 'crayon drawing', 'wax crayon'},\n",
    "    'chalk': {'chalk', 'red chalk', 'black chalk', 'color chalk'},\n",
    "    'lithography': {'lithograph', 'color lithograph', 'lithograph in colors'},\n",
    "    'pen': {'ballpoint pen', 'pen', 'black pen', 'colored pen', 'felt-tip pen'},\n",
    "    'ink, watercolor': {'ink, watercolor', 'india ink, watercolor', 'ink, pen, watercolor'},\n",
    "    'ink, pen': {'ink, pen', 'brown ink, pen'},\n",
    "    'watercolor, pencil': {'watercolor, pencil', 'watercolor over pencil', 'pencil, watercolor heightened with white'},\n",
    "    'oil, mixed media': {'mixed media, oil', 'collage, oil'},\n",
    "}\n",
    "\n",
    "    ## Composite matching rules ##\n",
    "# If a paint string contains multiple components (e.g., 'acrylic, gouache'), and all are present in the string,\n",
    "# it is assigned to the matching combined category (e.g., 'acrylic, gouache').\n",
    "double_paint_categories = {\n",
    "    'acrylic, gouache': {'acrylic', 'gouache'},\n",
    "    'gouache, watercolor': {'gouache', 'watercolor'},\n",
    "    'pencil, watercolor': {'pencil', 'watercolor'},\n",
    "    'ink, watercolor': {'ink', 'watercolor'},\n",
    "    'ink, pen': {'ink', 'pen'},\n",
    "    'oil, mixed media': {'oil', 'mixed media'},\n",
    "    'acrylic, mixed media': {'acrylic', 'mixed media'},\n",
    "}\n",
    "\n",
    "    ## Priority order for fallback ##\n",
    "# If no exact or composite match is found, the fallback logic searches for the first keyword\n",
    "# in the string that matches this priority list.\n",
    "fallback_priority = ['oil', 'watercolor', 'acrylic', 'ink', 'mixed media', 'gouache', 'pencil', 'pastel', 'charcoal', 'tempera', 'chalk', 'enamel', 'pen', 'lithograph']\n",
    "\n",
    "## Matching Functions ##\n",
    "# Maps a paint string to a standardized label using the exact_matches dictionary.\n",
    "def group_paint(paint):\n",
    "    if pd.isnull(paint):\n",
    "        return None\n",
    "    p = paint.lower().strip()\n",
    "    for label, terms in exact_matches.items():\n",
    "        if p in terms:\n",
    "            return label\n",
    "    return p\n",
    "\n",
    "# First tries to match composite terms, then falls back to keyword search.\n",
    "def group_paint_complex(paint):\n",
    "    if pd.isnull(paint):\n",
    "        return None\n",
    "    p = paint.lower().strip()\n",
    "    for label, comps in double_paint_categories.items():\n",
    "        if all(comp in p for comp in comps):\n",
    "            return label\n",
    "    for keyword in fallback_priority:\n",
    "        if keyword in p:\n",
    "            return keyword\n",
    "    return p\n",
    "\n",
    "df['Paint Grouped'] = df['Paint'].apply(group_paint).apply(group_paint_complex)\n",
    "\n",
    "top_paints = df['Paint Grouped'].value_counts()\n",
    "print(top_paints[:20])\n",
    "print(f\"Number of unique paint categories: {df['Paint Grouped'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Values of Material\n",
    "unique_materials = df['Material'].dropna().unique()\n",
    "print(f\"Unique Material ({len(unique_materials)}):\")\n",
    "\n",
    "top_materials = df['Material'].str.strip().str.lower().value_counts()\n",
    "print(top_materials[0:20])\n",
    "print(f\"Number of unique material categories: {df['Material'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Define Grouping Rules for Material\n",
    "# ----------------------------------------\n",
    "\n",
    "# Exact matching sets for key material types\n",
    "# These sets contain known variants/synonyms that map to standardized material categories\n",
    "exact_matches_board = {\n",
    "    \"artist's board\", \"fiberboard\", \"artist board\", \"composition board\",\n",
    "    \"fibreboard\", \"hardboard\", \"illustration board\", \"academy board\",\n",
    "    \"board, oval\", \"mdf\", \"pavatex\", \"light board\", \"board, in artist's frame\", \n",
    "    \"thin board\", \"cut out board\", \"hard fiberboard\", \"high-density fiberboard\"\n",
    "}\n",
    "\n",
    "exact_matches_panel = {\n",
    "    \"oak panel\", \"cradled panel\", \"mahogany panel\", \"birch panel\",\n",
    "    \"panel, unframed\", \"panel, en grisaille\", \"shaped panel\", \n",
    "    \"cradled oak panel\", \"uncradled panel\", \"uncradled oak panel\",\n",
    "    \"gold ground panel\"\n",
    "}\n",
    "\n",
    "# Paper variants\n",
    "paper_other_terms = {\n",
    "    \"laid paper\", \"wove paper\", \"cream wove paper\", \"buff paper\", \n",
    "    \"handmade paper\", \"tracing paper\", \"arches paper\", \"cream laid paper\",\n",
    "    \"paper, hanging scroll \", \"japanese paper\", \"japan paper\", \"newspaper\"\n",
    "}\n",
    "\n",
    "paper_terms = {\n",
    "    \"watercolor paper\", \"beige paper\", \"blue paper\", \"brown paper\",\n",
    "    \"paper, framed\", \"black paper\", \"grey paper\", \"paper laid down on paper\",\n",
    "    \"light brown paper\", \"gray paper\"\n",
    "}\n",
    "\n",
    "# Fabrics sometimes used as canvas\n",
    "canvas_fabrics = {\"hessian\", \"jute\", \"burlap\"}\n",
    "\n",
    "# Terms to preserve — prevent them from being collapsed in the next steps\n",
    "preserve_canvas_terms = {\n",
    "    'canvas', 'canvas, board', 'canvas, panel', 'canvas, paper'\n",
    "}\n",
    "\n",
    "preserve_paper_terms = {\n",
    "    'paper', 'canvas, paper', 'paper, board', 'paper, panel', 'wove paper'\n",
    "}\n",
    "\n",
    "preserve_board_terms = {\n",
    "    'canvas, board', 'paper, board'\n",
    "}\n",
    "\n",
    "preserve_panel_terms = {\n",
    "    'canvas, panel', 'paper, panel', 'panel'\n",
    "}\n",
    "\n",
    "# Function to group materials based on known matches and keywords\n",
    "def group_material(material):\n",
    "    \"\"\"\n",
    "    Assigns a standardized material label based on known matches and keywords.\n",
    "    Covers common material combinations and fallbacks.\n",
    "    \"\"\"\n",
    "    if pd.isnull(material):\n",
    "        return None\n",
    "    mat = material.lower().strip()\n",
    "\n",
    "    # Composite materials (multi-material combinations)\n",
    "    if 'paper' in mat and 'canvas' in mat:\n",
    "        return 'canvas, paper'\n",
    "    if 'canvas' in mat and 'panel' in mat:\n",
    "        return 'canvas, panel'\n",
    "    if 'canvas' in mat and 'board' in mat:\n",
    "        return 'canvas, board'\n",
    "    if 'paper' in mat and 'board' in mat:\n",
    "        return 'paper, board'\n",
    "    if 'paper' in mat and 'panel' in mat:\n",
    "        return 'paper, panel'\n",
    "\n",
    "    # Exact matches to predefined categories\n",
    "    if mat in exact_matches_board:\n",
    "        return 'board'\n",
    "    if mat in exact_matches_panel:\n",
    "        return 'panel'\n",
    "    if mat in paper_other_terms:\n",
    "        return 'paper, other'\n",
    "    if mat in paper_terms:\n",
    "        return 'paper'\n",
    "    if mat in canvas_fabrics:\n",
    "        return 'canvas'\n",
    "\n",
    "    # Keyword-based fallback matching\n",
    "    if 'wood' in mat or 'oak' in mat or 'mahogany' in mat:\n",
    "        return 'wood'\n",
    "    if 'masonite' in mat or 'isorel' in mat:\n",
    "        return 'masonite'\n",
    "    if 'silk' in mat or 'satin' in mat:\n",
    "        return 'silk'\n",
    "    if 'vellum' in mat or 'velum' in mat:\n",
    "        return 'vellum'\n",
    "    if 'glass' in mat or 'plexiglass' in mat or 'plexiglas' in mat or 'perspex' in mat:\n",
    "        return 'glass'\n",
    "    if 'cardboard' in mat:\n",
    "        return 'cardboard'\n",
    "    if 'linen' in mat:\n",
    "        return 'linen'\n",
    "    if 'copper' in mat:\n",
    "        return 'copper'\n",
    "\n",
    "    \n",
    "    return mat\n",
    "\n",
    "# Apply initial grouping\n",
    "df['Material Grouped'] = df['Material'].apply(group_material)\n",
    "\n",
    "\n",
    "# These functions further reduce granularity by consolidating near-duplicate terms\n",
    "# while preserving key terms like 'canvas, panel', etc.\n",
    "def final_canvas_grouping(mat):\n",
    "    if pd.isnull(mat):\n",
    "        return None\n",
    "    mat = mat.lower().strip()\n",
    "    if 'canvas' in mat and mat not in preserve_canvas_terms:\n",
    "        return 'canvas'\n",
    "    return mat\n",
    "\n",
    "def final_paper_grouping(mat):\n",
    "    if pd.isnull(mat):\n",
    "        return None\n",
    "    mat = mat.lower().strip()\n",
    "    if 'paper' in mat and mat not in preserve_paper_terms:\n",
    "        return 'paper, other'\n",
    "    return mat\n",
    "\n",
    "def final_board_grouping(mat):\n",
    "    if pd.isnull(mat):\n",
    "        return None\n",
    "    mat = mat.lower().strip()\n",
    "    if 'board' in mat and mat not in preserve_board_terms and 'cardboard' not in mat:\n",
    "        return 'board'\n",
    "    return mat\n",
    "\n",
    "def final_panel_grouping(mat):\n",
    "    if pd.isnull(mat):\n",
    "        return None\n",
    "    mat = mat.lower().strip()\n",
    "    if 'panel' in mat and mat not in preserve_panel_terms:\n",
    "        return 'panel'\n",
    "    return mat\n",
    "\n",
    "# Apply all four refinement stages\n",
    "df['Material Final'] = df['Material Grouped'].apply(final_canvas_grouping)\n",
    "df['Material Final'] = df['Material Final'].apply(final_paper_grouping)\n",
    "df['Material Final'] = df['Material Final'].apply(final_board_grouping)\n",
    "df['Material Final'] = df['Material Final'].apply(final_panel_grouping)\n",
    "\n",
    "\n",
    "top_materials = df['Material Final'].value_counts()\n",
    "print(top_materials[:20])\n",
    "print(f\"Number of unique material categories: {df['Material Final'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Finalizing Material and Paint Grouping\n",
    "# ----------------------------------------\n",
    "\n",
    "# Collapse Rare Material Categories into 'other'\n",
    "# Keep the top 20 most frequent material types\n",
    "top_20_materials = df['Material Final'].value_counts().head(20).index.tolist()\n",
    "\n",
    "def collapse_material_to_top_20(mat):\n",
    "    \"\"\"\n",
    "    Returns the material if it's among the top 20; otherwise 'other'.\n",
    "    NaNs are preserved as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isnull(mat):\n",
    "        return None\n",
    "    mat = mat.lower().strip()\n",
    "    return mat if mat in top_20_materials else \"other\"\n",
    "\n",
    "df['Material Final Cleaned'] = df['Material Final'].apply(collapse_material_to_top_20)\n",
    "\n",
    "# Collapse Rare Paint Categories into 'other'\n",
    "# Keep the top 28 most frequent paint types\n",
    "top_28_paints = df['Paint Grouped'].value_counts().head(28).index.tolist()\n",
    "\n",
    "def collapse_paint_to_top_28(paint):\n",
    "    \"\"\"\n",
    "    Returns the paint type if it's among the top 28; otherwise 'other'.\n",
    "    NaNs are preserved as NaN.\n",
    "    \"\"\"\n",
    "    if pd.isnull(paint):\n",
    "        return None\n",
    "    paint = paint.lower().strip()\n",
    "    return paint if paint in top_28_paints else \"other\"\n",
    "\n",
    "df['Paint Final'] = df['Paint Grouped'].apply(collapse_paint_to_top_28)\n",
    "\n",
    "print(f\"Number of unique material categories: {df['Material Final Cleaned'].nunique()}\") # 21\n",
    "print(f\"Number of unique paint categories: {df['Paint Final'].nunique()}\") # 29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Paint-Material Co-Occurrence Table\n",
    "# ----------------------------------------\n",
    "\n",
    "## Table showing the percentage of each material used with each paint type ##\n",
    "\n",
    "# Use cleaned columns\n",
    "paint_col = 'Paint Final'\n",
    "material_col = 'Material Final Cleaned'\n",
    "\n",
    "# Get updated top values based on cleaned columns\n",
    "top_paints = df[paint_col].value_counts().head(28).index.tolist()\n",
    "top_materials = df[material_col].value_counts().head(20).index.tolist()\n",
    "\n",
    "# Initialize a dictionary to store co-occurrence percentages\n",
    "from collections import defaultdict\n",
    "paint_to_material_pct = defaultdict(dict)\n",
    "\n",
    "# Loop through each top paint and calculate material usage percentages\n",
    "for paint in top_paints:\n",
    "    filtered = df[df[paint_col] == paint]\n",
    "    total_paint_count = len(filtered)\n",
    "    \n",
    "    if total_paint_count == 0:\n",
    "        continue\n",
    "\n",
    "    material_counts = filtered[material_col].value_counts()\n",
    "    for material in top_materials:\n",
    "        count = material_counts.get(material, 0)\n",
    "        pct = round(100 * count / total_paint_count, 2)\n",
    "        paint_to_material_pct[paint][material] = pct\n",
    "\n",
    "# Convert to a DataFrame for easy visualization and analysis\n",
    "paint_material_pct_df = pd.DataFrame(paint_to_material_pct).fillna(0)\n",
    "\n",
    "# Reorder rows and columns to match top material/paint order\n",
    "paint_material_pct_df = paint_material_pct_df.loc[top_materials, top_paints]\n",
    "\n",
    "#  Display Paint–Material Matrix\n",
    "print(\"Paint–Material Conditional Percentage Matrix:\")\n",
    "print(paint_material_pct_df.round(2))\n",
    "\n",
    "# Missing Values After Collapsing\n",
    "print(\"Missing values in 'Paint Final':\", df['Paint Final'].isnull().sum())\n",
    "print(\"Missing values in 'Material Final Cleaned':\", df['Material Final Cleaned'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Examine Missing Paint and Material Data by Artist\n",
    "# ----------------------------------------\n",
    "\n",
    "# Count missing material values per artist\n",
    "missing_material_counts = (\n",
    "    df[df['Material Final Cleaned'].isnull()]\n",
    "    .groupby('Artist Name')\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "missing_material_counts.name = 'Missing Material Count'\n",
    "\n",
    "# Count missing paint values per artist\n",
    "missing_paint_counts = (\n",
    "    df[df['Paint Final'].isnull()]\n",
    "    .groupby('Artist Name')\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "missing_paint_counts.name = 'Missing Paint Count'\n",
    "\n",
    "# Combine both counts into one DataFrame\n",
    "missing_counts = pd.concat([missing_material_counts, missing_paint_counts], axis=1).fillna(0).astype(int)\n",
    "\n",
    "# Display top 20 artists with the most missing values\n",
    "print(\"Top 20 artists with missing paint or material data:\")\n",
    "print(missing_counts.head(20))\n",
    "\n",
    "\n",
    "## Artists missing exactly one paint or material entry ##\n",
    "artists_missing_one = missing_counts[\n",
    "    (missing_counts['Missing Material Count'] + missing_counts['Missing Paint Count']) == 1\n",
    "]\n",
    "\n",
    "print(f\"Artists missing exactly 1 paint or material entry: {len(artists_missing_one)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# First Round of Imputation: Artist-Based\n",
    "# ----------------------------------------\n",
    "\n",
    "# This step imputes missing values in 'Paint' and 'Material' based\n",
    "# on observed co-occurrence patterns within each artist's known works.\n",
    "#\n",
    "# For artists with less than 35% missing data in both fields:\n",
    "#   - If 'Paint' is missing but 'Material' is known:\n",
    "#       → Sample a likely paint type used with that material\n",
    "#         based on the artist's other artworks.\n",
    "#   - If 'Material' is missing but 'Paint' is known:\n",
    "#       → Sample a likely material used with that paint\n",
    "#         based on the same artist's known combinations.\n",
    "#\n",
    "# This approach ensures imputations are:\n",
    "#   - Artist-specific\n",
    "#   - Reflective of actual historical usage patterns\n",
    "\n",
    "# Step 1: Count Missing Paint and Material Entries Per Artist\n",
    "missing_material_counts = (\n",
    "    df[df['Material Final Cleaned'].isnull()]\n",
    "    .groupby('Artist Name').size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "missing_material_counts.name = 'Missing Material Count'\n",
    "\n",
    "missing_paint_counts = (\n",
    "    df[df['Paint Final'].isnull()]\n",
    "    .groupby('Artist Name').size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "missing_paint_counts.name = 'Missing Paint Count'\n",
    "\n",
    "# Combine counts and compute total + missing %\n",
    "combined_missing = pd.concat([missing_material_counts, missing_paint_counts], axis=1).fillna(0).astype(int)\n",
    "combined_missing['Total Artworks'] = df.groupby('Artist Name').size()\n",
    "combined_missing['Missing Material %'] = (combined_missing['Missing Material Count'] / combined_missing['Total Artworks']).round(3)\n",
    "combined_missing['Missing Paint %'] = (combined_missing['Missing Paint Count'] / combined_missing['Total Artworks']).round(3)\n",
    "\n",
    "# Step 2: Identify Eligible Artists (less than 35% missing in both)\n",
    "threshold = 0.35\n",
    "eligible_artists = combined_missing[\n",
    "    (combined_missing['Missing Material %'] < threshold) &\n",
    "    (combined_missing['Missing Paint %'] < threshold)\n",
    "].index.tolist()\n",
    "\n",
    "# Step 3: Imputation Function Using Artist-Specific Co-occurrence\n",
    "def impute_paint_or_material(row, df):\n",
    "    artist = row['Artist Name']\n",
    "    known_material = row['Material Final Cleaned']\n",
    "    known_paint = row['Paint Final']\n",
    "    artist_df = df[df['Artist Name'] == artist]\n",
    "\n",
    "    # Impute Paint based on known Material\n",
    "    if pd.isnull(known_paint) and pd.notnull(known_material):\n",
    "        subset = artist_df[(artist_df['Paint Final'].notnull()) &\n",
    "                           (artist_df['Material Final Cleaned'] == known_material)]\n",
    "        if not subset.empty:\n",
    "            dist = subset['Paint Final'].value_counts(normalize=True)\n",
    "            return np.random.choice(dist.index, p=dist.values)\n",
    "\n",
    "    # Impute Material based on known Paint\n",
    "    if pd.isnull(known_material) and pd.notnull(known_paint):\n",
    "        subset = artist_df[(artist_df['Material Final Cleaned'].notnull()) &\n",
    "                           (artist_df['Paint Final'] == known_paint)]\n",
    "        if not subset.empty:\n",
    "            dist = subset['Material Final Cleaned'].value_counts(normalize=True)\n",
    "            return np.random.choice(dist.index, p=dist.values)\n",
    "\n",
    "    # If nothing can be inferred, return existing value\n",
    "    return known_paint if pd.isnull(known_material) else known_material\n",
    "\n",
    "# Step 4: Apply Imputation\n",
    "# Paint imputation\n",
    "missing_paint_mask = (\n",
    "    df['Artist Name'].isin(eligible_artists) &\n",
    "    df['Paint Final'].isnull() &\n",
    "    df['Material Final Cleaned'].notnull()\n",
    ")\n",
    "\n",
    "df.loc[missing_paint_mask, 'Paint Final Imputed'] = df[missing_paint_mask].apply(\n",
    "    lambda row: impute_paint_or_material(row, df), axis=1\n",
    ")\n",
    "\n",
    "# Material imputation\n",
    "missing_material_mask = (\n",
    "    df['Artist Name'].isin(eligible_artists) &\n",
    "    df['Material Final Cleaned'].isnull() &\n",
    "    df['Paint Final'].notnull()\n",
    ")\n",
    "\n",
    "df.loc[missing_material_mask, 'Material Final Imputed'] = df[missing_material_mask].apply(\n",
    "    lambda row: impute_paint_or_material(row, df), axis=1\n",
    ")\n",
    "\n",
    "# Step 5: Fill in All Remaining Nulls with Original Values (for completeness)\n",
    "df['Paint Final Imputed'] = df['Paint Final Imputed'].fillna(df['Paint Final'])\n",
    "df['Material Final Imputed'] = df['Material Final Imputed'].fillna(df['Material Final Cleaned'])\n",
    "\n",
    "## Summary of Imputation ##\n",
    "# Per artist (for diagnostics, optional to print)\n",
    "final_missing_material = df[df['Material Final Imputed'].isnull()]\\\n",
    "    .groupby('Artist Name').size().sort_values(ascending=False)\n",
    "final_missing_material.name = 'Missing Material After'\n",
    "\n",
    "final_missing_paint = df[df['Paint Final Imputed'].isnull()]\\\n",
    "    .groupby('Artist Name').size().sort_values(ascending=False)\n",
    "final_missing_paint.name = 'Missing Paint After'\n",
    "\n",
    "final_combined_missing = pd.concat([final_missing_material, final_missing_paint], axis=1).fillna(0).astype(int)\n",
    "\n",
    "# Overall missing value summary\n",
    "overall_missing_summary = pd.DataFrame({\n",
    "    'Missing Values': df[['Paint Final Imputed', 'Material Final Imputed']].isnull().sum(),\n",
    "    'Percent Missing (%)': df[['Paint Final Imputed', 'Material Final Imputed']].isnull().mean() * 100\n",
    "}).round(2)\n",
    "\n",
    "# Step 7: Collapse Long-Tail Categories After Imputation\n",
    "df['Paint Final Imputed Collapsed'] = df['Paint Final Imputed'].apply(collapse_paint_to_top_28)\n",
    "df['Material Final Imputed Collapsed'] = df['Material Final Imputed'].apply(collapse_material_to_top_20)\n",
    "\n",
    "# Print Summary\n",
    "print(\"Imputation Summary:\")\n",
    "print(overall_missing_summary)\n",
    "print(\"Unique Paints After Imputation:\", df['Paint Final Imputed Collapsed'].nunique(dropna=True))\n",
    "print(\"Unique Materials After Imputation:\", df['Material Final Imputed Collapsed'].nunique(dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Second Round of Imputation: High-Volume Artists (≥150 entries)\n",
    "# ---------------------------------------------------------------\n",
    "# This second imputation step targets artists who were not included \n",
    "# in the first round but have a large number of artworks with known \n",
    "# paint or material labels (≥150 entries).\n",
    "#\n",
    "# For each of these high-volume artists:\n",
    "#   - If 'Paint' is missing but 'Material' is known, we impute paint \n",
    "#     by sampling from the artist's observed paint distribution for \n",
    "#     that material.\n",
    "#   - If 'Material' is missing but 'Paint' is known, we impute material \n",
    "#     using the artist's distribution for that paint.\n",
    "\n",
    "\n",
    "## Identify High-Volume Artists ##\n",
    "# Count how many non-missing paint and material entries each artist has\n",
    "known_paint_counts = df[df['Paint Final Imputed Collapsed'].notnull()]\\\n",
    "    .groupby('Artist Name').size()\n",
    "\n",
    "known_material_counts = df[df['Material Final Imputed Collapsed'].notnull()]\\\n",
    "    .groupby('Artist Name').size()\n",
    "\n",
    "# Select artists with ≥150 known entries in either paint or material\n",
    "second_pass_artists = [\n",
    "    artist for artist in df['Artist Name'].unique()\n",
    "    if known_paint_counts.get(artist, 0) >= 150 or known_material_counts.get(artist, 0) >= 150\n",
    "]\n",
    "\n",
    "# Remove artists already imputed in the first round\n",
    "first_pass_artists = set(eligible_artists)  # from previous imputation step\n",
    "second_pass_only = [a for a in second_pass_artists if a not in first_pass_artists]\n",
    "\n",
    "## Define Masks for Missing Paint or Material ## \n",
    "# These masks identify which entries are still missing and can now be imputed\n",
    "second_missing_paint_mask = (\n",
    "    df['Artist Name'].isin(second_pass_only) &\n",
    "    df['Paint Final Imputed Collapsed'].isnull() &\n",
    "    df['Material Final Imputed Collapsed'].notnull()\n",
    ")\n",
    "\n",
    "second_missing_material_mask = (\n",
    "    df['Artist Name'].isin(second_pass_only) &\n",
    "    df['Material Final Imputed Collapsed'].isnull() &\n",
    "    df['Paint Final Imputed Collapsed'].notnull()\n",
    ")\n",
    "\n",
    "## Apply Imputation ##\n",
    "df.loc[second_missing_paint_mask, 'Paint Final Imputed Collapsed'] = df[second_missing_paint_mask].apply(\n",
    "    lambda row: impute_paint_or_material(row, df), axis=1\n",
    ")\n",
    "\n",
    "df.loc[second_missing_material_mask, 'Material Final Imputed Collapsed'] = df[second_missing_material_mask].apply(\n",
    "    lambda row: impute_paint_or_material(row, df), axis=1\n",
    ")\n",
    "\n",
    "# Recalculate Overall Missingness After Second Imputation\n",
    "overall_missing_summary = pd.DataFrame({\n",
    "    'Missing Values': df[['Paint Final Imputed Collapsed', 'Material Final Imputed Collapsed']].isnull().sum(),\n",
    "    'Percent Missing (%)': df[['Paint Final Imputed Collapsed', 'Material Final Imputed Collapsed']].isnull().mean() * 100\n",
    "}).round(2)\n",
    "df['Paint Final Imputed Collapsed'] = df['Paint Final Imputed Collapsed'].apply(collapse_paint_to_top_28)\n",
    "df['Material Final Imputed Collapsed'] = df['Material Final Imputed Collapsed'].apply(collapse_material_to_top_20)\n",
    "\n",
    "# Print Final Summary\n",
    "print(\"Second Imputation Summary:\")\n",
    "print(overall_missing_summary)\n",
    "print(\"Unique Paints After 2nd Imputation:\", df['Paint Final Imputed Collapsed'].nunique(dropna=True))\n",
    "print(\"Unique Materials After 2nd Imputation:\", df['Material Final Imputed Collapsed'].nunique(dropna=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Final Dataset Cleanup: Remove Remaining Missing Values\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Keep only rows with both paint and material fully imputed\n",
    "df_final = df[\n",
    "    df['Paint Final Imputed Collapsed'].notnull() &\n",
    "    df['Material Final Imputed Collapsed'].notnull()\n",
    "].copy()\n",
    "\n",
    "# Summary after removing artworks missing both labels\n",
    "print(f\"Final dataset size after imputation filter: {len(df_final)} artworks\")\n",
    "print(f\"Remaining missing in 'Paint': {df_final['Paint Final Imputed Collapsed'].isnull().sum()}\")\n",
    "print(f\"Remaining missing in 'Material': {df_final['Material Final Imputed Collapsed'].isnull().sum()}\")\n",
    "\n",
    "# Remove entries with missing 'Area' values (important for modeling)\n",
    "df_final = df_final[df_final['Area'].notnull()].copy()\n",
    "\n",
    "# Summary of remaining missing values in other columns\n",
    "missing_counts = df_final.isnull().sum()\n",
    "missing_percent = df_final.isnull().mean() * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Values': missing_counts,\n",
    "    'Percent Missing (%)': missing_percent.round(2)\n",
    "})\n",
    "\n",
    "missing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Subset Final DataFrame to Relevant Columns for Modeling/Export\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "selected_columns = [\n",
    "    'Title Cleaned', 'Year of Creation', 'Artist ID', 'Artist Name', 'Dimensions', 'Log Area',\n",
    "    'Sale Date Cleaned', 'Auction House', 'Sale Location', 'Sale Name', 'Lot Number',\n",
    "    'Price Sold USD', 'Image url better quality', 'Country', 'Year of Birth', 'Year of Death',\n",
    "    'Birth Period', 'Birth Period Ordinal' ,'Sale Year', 'CPI_US', 'Alive Status',\n",
    "    'Paint Final Imputed Collapsed', 'Material Final Imputed Collapsed'\n",
    "]\n",
    "\n",
    "df_subset = df_final[selected_columns].copy()\n",
    "\n",
    "print(f\"Subset shape: {df_subset.shape}\")\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_subset.columns[4:]:\n",
    "    unique_vals = df_subset[col].nunique()\n",
    "    print(f\"{col}: {unique_vals} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Filter Artworks to Post-War Period (1945–1970) and Save to File\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Handle missing years by temporarily replacing them with 9999\n",
    "year_created = df_subset['Year of Creation'].fillna(9999).astype(int)\n",
    "\n",
    "# Post-War artworks (1945–1970)\n",
    "post_war_mask = (year_created >= 1945) & (year_created <= 1970)\n",
    "\n",
    "# Subset and reset index\n",
    "df_postwar = df_subset[post_war_mask].reset_index(drop=True).copy()\n",
    "\n",
    "# Save filtered dataset as a pickle file\n",
    "df_postwar.to_pickle(\"Datasets/df_postwar.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArtAuction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
