{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "---------------------------------------------------------\n",
    "Data Preprocessing Script (Step 1): Feature Engineering and Filtering\n",
    "---------------------------------------------------------\n",
    "\n",
    "This script performs the first stage of data processing for the artwork price prediction pipeline. \n",
    "It reads and merges auction and artist data, creates new variables, standardizes categorical values, \n",
    "and filters the dataset in preparation for imputation and modeling.\n",
    "\n",
    "Main Tasks:\n",
    "-----------\n",
    "1. **Load Data**:\n",
    "   - Loads auction results and artist metadata from pickle files.\n",
    "   - Loads and normalizes U.S. CPI data for inflation adjustment.\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Extracts and cleans artist country, year of birth/death.\n",
    "   - Derives \"Birth Period\" and \"Alive Status at Time of Sale\".\n",
    "   - Adds \"Sale Year\" and maps CPI based on year of sale.\n",
    "\n",
    "3. **Category Processing**:\n",
    "   - Groups infrequent countries into \"Others\" (top 40 retained).\n",
    "   - Groups infrequent auction houses into \"Others\" (top 100 retained).\n",
    "\n",
    "4. **Filtering**:\n",
    "   - Removes rows where final sale price or sale date is missing.\n",
    "   - Reports missing data summary before and after filtering.\n",
    "\n",
    "Inputs:\n",
    "-------\n",
    "- 'Cleaned_Data/auction_results_cleaned.pickle' : list of auction results \n",
    "- 'Cleaned_Data/artists_details.pickle'         : list of artist metadata (Name, Country, Biography)\n",
    "- 'cpi_us.csv'                                   : inflation index data\n",
    "\n",
    "Output:\n",
    "-------\n",
    "- `df` : a cleaned, CPI-adjusted DataFrame with engineered features\n",
    "         ready for imputation of paint and material fields in the next step.\n",
    "\n",
    "Next Step:\n",
    "----------\n",
    "- Imputation of 'Material' and 'Paint' columns.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('Art-Valuation-in-Auction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Pickle File Function\n",
    "def read_pickle_to_dataframe(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = []\n",
    "            while True:\n",
    "                try:\n",
    "                    obj = pickle.load(f)\n",
    "                    if isinstance(obj, list):\n",
    "                        data.extend(obj)\n",
    "                    else:\n",
    "                        data.append(obj)\n",
    "                except EOFError:\n",
    "                    break\n",
    "        print(f\"Loaded {len(data)} records.\")\n",
    "        df = pd.DataFrame(data)\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading pickle file: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Load Auction and Artist Data\n",
    "# -------------------------------\n",
    "df = read_pickle_to_dataframe(\"Datasets/auction_results_cleaned.pickle\")\n",
    "\n",
    "artists_details = read_pickle_to_dataframe('Datasets/artists_details.pickle')\n",
    "artists_details_df = pd.DataFrame(artists_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Extract Country and Date of Birth from Artist Metadata\n",
    "# -------------------------------\n",
    "def clean_country_year(country_year):\n",
    "    \n",
    "    \"\"\"\n",
    "     Parses 'country, YYYY–YYYY' string into components:\n",
    "        - Country\n",
    "        - Year of Birth (yob)\n",
    "        - Year of Death (yod)\n",
    "    \"\"\"\n",
    "\n",
    "    country, year = '', ''\n",
    "    yob, yod = np.nan, np.nan\n",
    "\n",
    "    if pd.isnull(country_year):\n",
    "        return pd.Series([country, yob, yod])\n",
    "\n",
    "    country_year = re.split(',', country_year.strip(), maxsplit=1)\n",
    "\n",
    "    if len(country_year) == 2:\n",
    "        country, year = country_year\n",
    "    elif len(country_year) == 1:\n",
    "        if re.search(r'\\d{2,}', country_year[0]):\n",
    "            year = country_year[0]\n",
    "        else:\n",
    "            country = country_year[0]\n",
    "\n",
    "    if '-' in year or '–' in year:\n",
    "        year = re.findall(r'(?:^|\\D)(\\d+)\\s*[–\\-]\\s*(\\d+)(?:$|\\D)', year)\n",
    "        if len(year) == 1:\n",
    "            year = year[0]\n",
    "            if len(year) == 2:\n",
    "                yob, yod = year\n",
    "                yob = int(yob) if len(yob) == 4 else np.nan\n",
    "                yod = int(yod) if len(yod) == 4 else np.nan\n",
    "\n",
    "    elif year != '':\n",
    "        yob = re.findall(r'(?:^|\\D)(\\d{4})(?:\\D|$)', year)\n",
    "        yob = int(yob[0]) if len(yob) == 1 else np.nan\n",
    "\n",
    "    return pd.Series([country.strip(), yob, yod])\n",
    "\n",
    "\n",
    "artists_details_df[['Country', 'Year of Birth', 'Year of Death']] = (\n",
    "    artists_details_df['artist_country_year'].apply(clean_country_year)\n",
    ")\n",
    "artists_details_df['Country'] = artists_details_df['Country'].replace('', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Log Area\n",
    "# -------------------------------\n",
    "df['Log Area'] = np.log(df['Area'].replace(0, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Derive Birth Period from Year of Birth\n",
    "# -------------------------------\n",
    "\n",
    "# Define Periods Manually\n",
    "periods_year = [0, 1400, 1600, 1750, 1850, 1950, 1970, 2025]\n",
    "labels = [f'{periods_year[i]}-{periods_year[i+1]}' for i in range(len(periods_year) - 1)]\n",
    "\n",
    "\n",
    "for i in range(len(periods_year) - 1):\n",
    "    mask = (artists_details_df['Year of Birth'] > periods_year[i]) & \\\n",
    "           (artists_details_df['Year of Birth'] <= periods_year[i + 1])\n",
    "    artists_details_df.loc[mask, 'Birth Period'] = labels[i]\n",
    "\n",
    "# Fill Missing Periods as 'Unknown'\n",
    "artists_details_df['Birth Period'] = artists_details_df['Birth Period'].fillna('Unknown')\n",
    "\n",
    "\n",
    "# Birth Period as Ordinal Category\n",
    "birth_period_order = labels + ['Unknown']\n",
    "birth_period_map = {label: i for i, label in enumerate(birth_period_order)}\n",
    "artists_details_df['Birth Period Ordinal'] = artists_details_df['Birth Period'].map(birth_period_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Merge Artist Metadata into Auction Data\n",
    "# ----------------------------------------\n",
    "\n",
    "df = df.merge(\n",
    "    artists_details_df[['artist_id', 'Country', 'Year of Birth', 'Year of Death', 'Birth Period', 'Birth Period Ordinal']],\n",
    "    how='left',\n",
    "    left_on='Artist ID',\n",
    "    right_on='artist_id'\n",
    ")\n",
    "df.drop(columns=['artist_id'], inplace=True)\n",
    "\n",
    "# Extract year from sale date for downstream use\n",
    "df['Sale Year'] = df['Sale Date Cleaned'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# US Consumer Price Index (CPI) Adjustment\n",
    "# ----------------------------------------\n",
    "\n",
    "# Load CPI data, use data from 1985 onwards\n",
    "# Our auctions range from 1985 (earliest) to 2025 (latest)\n",
    "cpi_us = pd.read_csv('cpi_us.csv', header=0)\n",
    "cpi_us.columns = ['YEAR', 'CPI']\n",
    "cpi_us = cpi_us[cpi_us['YEAR'] >= 1985].copy()\n",
    "cpi_us['CPI'] = cpi_us['CPI'].replace('–', np.nan).astype(float)\n",
    "\n",
    "# Normalize CPI to 1996 baseline\n",
    "cpi_us_1996 = cpi_us.loc[cpi_us['YEAR'] == 1996, 'CPI'].iloc[0]\n",
    "cpi_us['CPI'] = cpi_us['CPI'] / cpi_us_1996\n",
    "\n",
    "# Project 2025 CPI using estimated 2.6% inflation over 2024\n",
    "cpi_us_2024 = cpi_us.loc[cpi_us['YEAR'] == 2024, 'CPI'].iloc[0]\n",
    "cpi_us.loc[cpi_us['YEAR'] == 2025, 'CPI'] = cpi_us_2024 * 1.026\n",
    "\n",
    "# Map CPI to artworks based on sale year\n",
    "cpi_map = cpi_us.set_index('YEAR')['CPI'].to_dict()\n",
    "df['CPI_US'] = df['Sale Date Cleaned'].dt.year.map(cpi_map)\n",
    "\n",
    "# Identify any years in the data that are missing CPI info\n",
    "missing_years = set(df['Sale Date Cleaned'].dt.year.unique()) - set(cpi_map)\n",
    "if missing_years:\n",
    "    print(\"Missing CPI for years:\", missing_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Determine Whether Artist Was Alive at Time of Sale\n",
    "# ----------------------------------------\n",
    "\n",
    "def assign_alive_status(row):\n",
    "    \"\"\"\n",
    "    Assigns alive/dead status at time of sale:\n",
    "        - 1: Alive\n",
    "        - 0: Dead\n",
    "        - 'Unknown': if unknown\n",
    "    \n",
    "    Fallback estimation is used when year of death is missing:\n",
    "        - If artist was <50 years old → probably alive\n",
    "        - If artist was >100 years old → probably dead\n",
    "        - Otherwise → status remains 'Unknown'\n",
    "    \"\"\"\n",
    "    if pd.notnull(row['Year of Death']):\n",
    "        if row['Sale Year'] < row['Year of Death']:\n",
    "            return 1  # Alive\n",
    "        elif row['Sale Year'] > row['Year of Death']:\n",
    "            return 0  # Dead\n",
    "    else:\n",
    "        # Estimate based on age at time of sale\n",
    "        if row['Sale Year'] < row['Year of Birth'] + 50:\n",
    "            return 1  # Probably alive\n",
    "        elif row['Sale Year'] > row['Year of Birth'] + 100:\n",
    "            return 0  # Probably dead\n",
    "    return 'Unknown'  # Can't determine\n",
    "\n",
    "# Apply the logic row-wise\n",
    "df['Alive Status'] = df.apply(assign_alive_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Group Countries by Frequency\n",
    "# ----------------------------------------\n",
    "\n",
    "# Count frequency of each country\n",
    "country_summary = df['Country'].value_counts().reset_index()\n",
    "country_summary.columns = ['Country', 'count']\n",
    "country_summary['Rank'] = range(len(country_summary))\n",
    "country_summary['Cover'] = country_summary['count'].cumsum() / len(df)\n",
    "\n",
    "# Keep only the top 40 most frequent countries\n",
    "# All others will be grouped under 'Others' to reduce category cardinality\n",
    "top_countries = country_summary.head(40)['Country'].tolist()\n",
    "df['Country'] = df['Country'].where(df['Country'].isin(top_countries), other='Others')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Missing Value Summary (Before Filtering)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Count and percentage of missing values per column\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percent = df.isnull().mean() * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Values': missing_counts,\n",
    "    'Percent Missing (%)': missing_percent.round(2)\n",
    "})\n",
    "\n",
    "print(\"Missing values before filtering:\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Remove Rows with Missing Target or Date\n",
    "# ----------------------------------------\n",
    "\n",
    "df = df[df['Price Sold USD'].notnull()]         # Drop if final sale price is missing\n",
    "df = df[df['Sale Date Cleaned'].notnull()]      # Drop if sale date is missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Missing Value Summary (After Filtering)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Recompute missing value summary after filtering\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percent = df.isnull().mean() * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Values': missing_counts,\n",
    "    'Percent Missing (%)': missing_percent.round(2)\n",
    "})\n",
    "\n",
    "print(\"Missing values after filtering:\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Final Data Summary: Columns, Unique Values, Missing Values\n",
    "# ----------------------------------------\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Column Name': df.columns,\n",
    "    'Unique Values': [df[col].nunique(dropna=True) for col in df.columns],\n",
    "    'Missing Values': df.isnull().sum().values\n",
    "})\n",
    "\n",
    "print(\"Final Column Summary:\")\n",
    "print(summary_df.sort_values(by='Missing Values', ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Save Final DataFrame for Next Processing Step\n",
    "# ----------------------------------------\n",
    "\n",
    "output_path = \"Datasets/DataProcessing_Step1_df.pkl\"\n",
    "df.to_pickle(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
