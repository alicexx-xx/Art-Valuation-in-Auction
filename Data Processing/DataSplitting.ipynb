{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------\n",
    "# DataSplitting.ipynb\n",
    "# ---------------------------------------------------------------\n",
    "This script prepares the post-war dataset for modeling by:\n",
    "1. Log-transforming the target variable (Price Sold USD)\n",
    "2. Exploring sale date distribution\n",
    "3. Splitting the data chronologically into Train, Validation, and Test sets\n",
    "4. Creating artist-level rolling median price encodings based on past sales\n",
    "\n",
    "The chronological split ensures realistic forecasting conditions where \n",
    "future sales are predicted based only on past information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('Art-Valuation-in-Auction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_postwar = pd.read_pickle(\"Datasets/df_postwar.pkl\")\n",
    "\n",
    "df_postwar = df_postwar.rename(columns={\n",
    "    'Paint Final Imputed Collapsed': 'Paint Imputed',\n",
    "    'Material Final Imputed Collapsed': 'Material Imputed'\n",
    "})\n",
    "\n",
    "print(df_postwar.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Step 1: Log-transform the Target Variable\n",
    "# ---------------------------------------------------------------\n",
    "df_postwar['Log Price'] = np.log(df_postwar['Price Sold USD'])\n",
    "\n",
    "# Visualize log-transformed price distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_postwar['Log Price'], bins=100, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribution of Log-Transformed Artwork Prices\")\n",
    "plt.xlabel(\"Log(1 + Price Sold USD)\")\n",
    "plt.ylabel(\"Number of Artworks\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Step 2: Prepare Sale Dates for Chronological Splitting\n",
    "# ---------------------------------------------------------------\n",
    "df_postwar['Sale Date Cleaned'] = pd.to_datetime(df_postwar['Sale Date Cleaned'])\n",
    "\n",
    "# Confirm no missing dates\n",
    "num_missing_dates = df_postwar['Sale Date Cleaned'].isnull().sum()\n",
    "print(f\"Missing sale dates: {num_missing_dates}\")\n",
    "\n",
    "# Sort by sale date\n",
    "df_postwar = df_postwar.sort_values('Sale Date Cleaned').reset_index(drop=True)\n",
    "\n",
    "# Date range\n",
    "print(\"Min sale date:\", df_postwar['Sale Date Cleaned'].min())\n",
    "print(\"Max sale date:\", df_postwar['Sale Date Cleaned'].max())\n",
    "\n",
    "# Plot number of artworks per year\n",
    "df_postwar['Sale Year'] = df_postwar['Sale Date Cleaned'].dt.year\n",
    "year_counts = df_postwar['Sale Year'].value_counts().sort_index()\n",
    "\n",
    "year_counts.plot(kind='bar', figsize=(15, 5))\n",
    "plt.title(\"Number of Artworks Sold per Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Artworks\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Step 3: Compute Cut-off Years for Train / Val / Test Split\n",
    "# ---------------------------------------------------------------\n",
    "cumulative = year_counts.cumsum()\n",
    "total = cumulative.iloc[-1]\n",
    "\n",
    "train_year = cumulative[cumulative <= 0.75 * total].index.max()\n",
    "val_year = cumulative[cumulative <= 0.90 * total].index.max()\n",
    "\n",
    "print(\"Suggested chronological split:\")\n",
    "print(f\" - Train: <= {train_year}\")\n",
    "print(f\" - Validation: {train_year + 1} to {val_year}\")\n",
    "print(f\" - Test: > {val_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Step 4: Apply Train / Validation / Test Splits\n",
    "# ---------------------------------------------------------------\n",
    "train_df = df_postwar[df_postwar['Sale Year'] <= train_year].copy()\n",
    "val_df = df_postwar[(df_postwar['Sale Year'] > train_year) & (df_postwar['Sale Year'] <= val_year)].copy()\n",
    "test_df = df_postwar[df_postwar['Sale Year'] > val_year].copy()\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Validation size: {len(val_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Step 5: Encode Artist-Level Rolling Avg Sale Prices\n",
    "# ---------------------------------------------------------------\n",
    "def add_artist_history_features(df):\n",
    "    df = df.sort_values(\"Sale Date Cleaned\").copy()\n",
    "\n",
    "    # Cumulative price before artwork t\n",
    "    df[\"Artist Cumulative Price\"] = (\n",
    "        df.groupby(\"Artist Name\")[\"Price Sold USD\"]\n",
    "          .transform(lambda x: x.shift().cumsum())\n",
    "    )\n",
    "\n",
    "    # Ordered average price before artwork t\n",
    "    df[\"Artist Ordered Avg Price\"] = (\n",
    "        df.groupby(\"Artist Name\")[\"Price Sold USD\"]\n",
    "          .transform(lambda x: x.shift().expanding().mean())\n",
    "    )\n",
    "\n",
    "    # Drop first appearance of each artist (where shift leads to NaN)\n",
    "    df = df[\n",
    "        df[\"Artist Cumulative Price\"].notnull() &\n",
    "        df[\"Artist Ordered Avg Price\"].notnull()\n",
    "    ].copy()\n",
    "\n",
    "    # Count of prior sales\n",
    "    df[\"Artist Sale Count\"] = df.groupby(\"Artist Name\").cumcount()\n",
    "\n",
    "    # Log transforms\n",
    "    df[\"Artist Cumulative Price Log\"] = np.log(df[\"Artist Cumulative Price\"])\n",
    "    df[\"Artist Ordered Avg Price\"] = np.log(df[\"Artist Ordered Avg Price\"])\n",
    "    df[\"Artist Sale Count\"] = np.log1p(df[\"Artist Sale Count\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply to split datasets\n",
    "train_df = add_artist_history_features(train_df)\n",
    "val_df = add_artist_history_features(val_df)\n",
    "test_df = add_artist_history_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save as pickle files\n",
    "train_df.to_pickle(f\"Datasets/train_df.pkl\")\n",
    "val_df.to_pickle(f\"Datasets/val_df.pkl\")\n",
    "test_df.to_pickle(f\"Datasets/test_df.pkl\")\n",
    "\n",
    "print(train_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
